# Beytullah BektaÅŸ  
ğŸ“§ beytullahbektas19@gmail.com  

# ğŸ“Œ Pusula Intern Data Science 2025

This project was developed as part of the **Pusula Data Science Internship 2025**.  
The main goal is to perform **EDA (Exploratory Data Analysis)** and **Data Preprocessing** steps (cleaning, encoding, scaling, pipeline) on the provided patient dataset.  

---

## ğŸ” Project Workflow

### 1. Data Loading
- The dataset was provided in Excel format (`pusula_data.xlsx`).  
- Loaded using **pandas**.  

### 2. Exploratory Data Analysis (EDA)
- General statistics (`df.info()`, `df.describe()`)  
- Missing value analysis (`df.isnull().sum()`)  
- Visualizations:  
  - Age distribution  
  - Age vs Treatment Duration (scatter plot)  
  - Correlation matrix (heatmap)  

### 3. Data Cleaning
- Removed meaningless values such as `"nan"`, `"?"`, `"unknown"`.  

### 4. Missing Value Imputation
Missing values were handled according to the type of column:  
- **Numerical columns (`Yas`, `TedaviSuresi`, `UygulamaSuresi`)** â†’ filled with **median**.  
  - Median is more robust to outliers than mean.  
- **Categorical columns (`Cinsiyet`, `Uyruk`, `Bolum`, `KronikHastalik`, `Tanilar`, `TedaviAdi`, `UygulamaYerleri`)** â†’ filled with the **most frequent value (mode)**.  
  - This preserves the original distribution without introducing bias.  

### 5. Encoding
- **Small categorical features** (`Cinsiyet`, `Uyruk`, `Bolum`) â†’ OneHotEncoder  
- **Large categorical features** (`Tanilar`, `TedaviAdi`, `KronikHastalik`) â†’ grouped into Top N categories and then encoded with OneHotEncoder  

### 6. Scaling
- **StandardScaler** was applied to numerical columns:  
  - `Yas`  
  - `TedaviSuresi`  
  - `UygulamaSuresi`  

### 7. Pipeline
- All preprocessing steps (cleaning, encoding, scaling) were combined into a **Pipeline** for reproducibility.  
- Outputs:  
  - `pusula_clean_ready.xlsx` â†’ Cleaned dataset with imputed values  
  - `pipeline_ready.csv` â†’ Final pipeline output  

### 8. Comparison: Manual Encoding vs Pipeline
- Manual encoding + scaling and pipeline results were compared.  
- âœ… **Result:** Both methods produce the **same output** (except for very minor rounding differences).  

---

## ğŸ“ Project Structure
Pusula_Beytullah_BektaÅŸ/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original dataset
â”‚ â”œâ”€â”€ processed/ # Cleaned & processed datasets
â”‚
â”œâ”€â”€ notebooks/ # Jupyter Notebooks (EDA, Preprocessing, Pipeline)
â”‚
â”œâ”€â”€ pusula_manuel_encoded_ready.xlsx # Cleaned + imputed dataset
â”œâ”€â”€ pipeline_ready.csv # Pipeline output
â”œâ”€â”€ README.md # Project description


## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/username/Pusula_Beytullah_BektaÅŸ.git
   cd Pusula_Beytullah_BektaÅŸ
Install requirements:

bash
pip install -r requirements.txt
Run Jupyter notebooks:

bash
jupyter notebook


ğŸ‘¤ Author
Name: Beytullah BektaÅŸ

Internship: Pusula Data Science 2025

E-mail: beytullahbektas19@gmail.com


